import json
import os
import random
import shutil
from pathlib import Path

def split_coco_dataset_with_images(
    coco_json_path: str,
    source_images_dir: str,  # ì´ë¯¸ì§€ê°€ ë‹¤ ëª¨ì—¬ ìˆëŠ” ê²½ë¡œ
    output_base_dir: str,
    val_ratio: float = 0.15,
    random_seed: int = 42
):
    random.seed(random_seed)
    
    # 1. COCO JSON ë¡œë“œ
    print(f"ğŸ“¦ Loading COCO JSON: {coco_json_path}...")
    with open(coco_json_path, 'r', encoding='utf-8') as f:
        coco_data = json.load(f)
    
    images = coco_data.get('images', [])
    annotations = coco_data.get('annotations', [])
    categories = coco_data.get('categories', [])
    
    # 2. ì´ë¯¸ì§€ ID ë¦¬ìŠ¤íŠ¸ ë¶„í• 
    image_ids = [img['id'] for img in images]
    random.shuffle(image_ids)
    split_idx = int(len(image_ids) * (1 - val_ratio))
    train_ids = set(image_ids[:split_idx])
    val_ids = set(image_ids[split_idx:])
    
    # 3. ì¶œë ¥ ê²½ë¡œ ì„¤ì •
    train_img_out = Path(output_base_dir) / "images" / "train"
    val_img_out = Path(output_base_dir) / "images" / "val"
    ann_out = Path(output_base_dir) / "annotations"
    
    for d in [train_img_out, val_img_out, ann_out]:
        d.mkdir(parents=True, exist_ok=True)

    # 4. ì´ë¯¸ì§€ ë³µì‚¬ ë° ë°ì´í„° ì²˜ë¦¬
    def process_data(target_ids, split_name, target_dir):
        split_images = [img for img in images if img['id'] in target_ids]
        split_anns = [ann for ann in annotations if ann['image_id'] in target_ids]
        
        print(f"ğŸš€ [{split_name}] ì´ë¯¸ì§€ ë³µì‚¬ ì‹œì‘ (ëŒ€ìƒ: {len(split_images)}ê°œ)...")
        copied_count = 0
        missing_count = 0
        
        for img in split_images:
            file_name = img['file_name']
            src_path = Path(source_images_dir) / file_name
            dst_path = target_dir / file_name
            
            if src_path.exists():
                if not dst_path.exists():
                    shutil.copy2(src_path, dst_path)
                copied_count += 1
            else:
                missing_count += 1
        
        print(f"âœ… [{split_name}] ì™„ë£Œ: {copied_count}ê°œ ë³µì‚¬ (ëˆ„ë½: {missing_count}ê°œ)")
        return split_images, split_anns

    # 5. ì‹¤í–‰
    train_imgs, train_anns = process_data(train_ids, "Train", train_img_out)
    val_imgs, val_anns = process_data(val_ids, "Val", val_img_out)

    # 6. JSON ì €ì¥
    with open(ann_out / "train_coco.json", 'w', encoding='utf-8') as f:
        json.dump({"images": train_imgs, "annotations": train_anns, "categories": categories}, f, ensure_ascii=False, indent=2)
    with open(ann_out / "val_coco.json", 'w', encoding='utf-8') as f:
        json.dump({"images": val_imgs, "annotations": val_anns, "categories": categories}, f, ensure_ascii=False, indent=2)

    print(f"\nâœ¨ ëª¨ë“  ì‘ì—… ì™„ë£Œ! ì´ {len(images)}ì¥ ì¤‘ {copied_count + copied_count}ì¥ ì²˜ë¦¬ë¨.")

if __name__ == "__main__":
    INPUT_COCO = "/Users/ganghyeon-u/Desktop/ê°•ì›ëŒ€ ë¶€íŠ¸ìº í”„(ì¤‘ê¸‰)/code/model/train_coco.json"
    
    # ì´ë¯¸ì§€ê°€ ë‹¤ ëª¨ì—¬ ìˆë‹¤ê³  í•˜ì‹  ë°”ë¡œ ê·¸ ê²½ë¡œ!
    SOURCE_IMG_DIR = "/Users/ganghyeon-u/Desktop/ê°•ì›ëŒ€ ë¶€íŠ¸ìº í”„(ì¤‘ê¸‰)/code/model/dataset ì˜¤í›„ 4.31.14/images"
    
    OUTPUT_BASE = "/Users/ganghyeon-u/Desktop/ê°•ì›ëŒ€ ë¶€íŠ¸ìº í”„(ì¤‘ê¸‰)/code/model/dataset"
    
    split_coco_dataset_with_images(INPUT_COCO, SOURCE_IMG_DIR, OUTPUT_BASE)